# Comentarios semana 6: Deep Learning aplicado a recomendar

**Paper** Zhang, S., Yao, L., Sun, A., & Tay, Y. (2019). Deep learning based recommender system: A survey and new perspectives. ACM Computing Surveys (CSUR), 52(1), 1-38.

Recomendar apropiadamente puede ser una oportunidad para optimizar el consumo y por ende las ganancias, lo que lo convierte en un problema de millones de dólares. Para ello es esencial capturar el comportamiento de los usuarios y las relaciones entre los ítems. El estado del arte con respecto a la representación de datos no estructurados se encuentra en los modelos neuronales profundos y en consecuencia, es apropiado utilizar dichas técnica para mejorar los sistemas de recomendación.

En el paper se realiza un ordenado resumen de como se ha utilizado algunas técnicas populares de Deep Learning en sistemas recomendadores. La principal clasificación de modelos es la siguiente: Multilayer Perceptron (MLP), Autoencoder (AE), Convolutional Neuronal Network (CNN), Recurrent Neuronal Network (RNN), Restricted Boltzmann Machine (RBM), Neuronal Autoregressive Distribution Estimation (NADE), Adeversarial Networks (AN), Attentional Models (AM) & Deep Reinforcement Learning (DRL).

Algunas de las ventajas comunes de estos modelos son su capacidad de representar transformaciones no lineales y por tanto más complejos que los métodos de filtrado colaborativo tradicional, también se de destacan por ser eficientes extractores de características, lo cual reduce el trabajo humano de análisis, y además,  aportan flexibilidad de modelamiento e incluso permitiendo incorporar la temporalidad subyacente al sistema recomendador. El precio a pagar por estas ventajas, son principalmente la necesidad de grandes cantidades de datos, la escaza interpretabilidad de las recomendaciones y un alto tiempo de entramiento. Aunque cabe destacar que tales desventajas, no son generalmente grandes problemas en sistemas recomendadores, pues se recolectan datos de forma masiva y en tiempo real en las diversas industrias. Por otro lado, considerando los avances de hardware y la creación de modelos con menos parámetros, es que se convierte en una realidad la aplicabilidad de estos algoritmos a la industria. También, la interpretabilidad se puede lograr de cierta manera a través de la integración de mecanismos atencionales y técnicas de visualización. 

Debido a la naturaleza recopilatoria del trabajo, me centraré en comentar una de las ideas que considero más relevantes expuestas en el survey.

En information retrieval existen dos líneas de pensamiento principales. La generativa, que asume que existe un proceso subyacente de generación vinculante entre documentos y consultas. Y la discriminativa, que busca aprender a predecir un score de relevancia para una tupla documento-consulta. A través del uso de (GAN) es posible combinar ambos procesos de manera eficiente a través de una metodología tipo *min max* de teoría de juegos, esto es, considerar un enfrentamiento entre ambos pensamientos, reflejado en un *generador* que intenta generar documentos similares al ground truth, ósea muestrear los documentos relevantes, y un *discriminador* que busca identificar la naturaleza del documento (real o artificialmente generada), ósea, relevantes y no relevantes. Los modelos que se utilizan para generar y discriminar son a libre elección, ósea pueden ser basados en máquinas de factorización o redes neuronales, lo que considero una **oportunidad** para probar nuevos modelos recomendadores que tengan como base fundamental los recomendadores clásicos más estudiados, y evaluar diferentes tipos características deseables en el sistema de recomendación, junto a un estudio de integración de estas características en la metodología confrontacional *min max*.
